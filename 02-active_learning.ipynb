{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn\n",
    "import modAL\n",
    "from modAL.models import ActiveLearner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer\n",
    "import numpy as np\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.uncertainty import entropy_sampling\n",
    "from modAL.uncertainty import margin_sampling\n",
    "from modAL.utils.selection import multi_argmax\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import audio_decryption\n",
    "import IPython.display\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/scratch/yw3004/projects/ICASSP2019-AL/'\n",
    "data_path = os.path.join(project_path, 'data')\n",
    "model_path = os.path.join(project_path, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Load Data and Train Initial Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1,6):\n",
    "    X_train = pickle.load(open(os.path.join(data_path, 'X_train_all_'+str(cv)+'.pickle'), \"rb\" ))\n",
    "    y_train = pickle.load(open(os.path.join(data_path, 'y_train_all_'+str(cv)+'.pickle'), \"rb\" ))\n",
    "    \n",
    "    clf_trainall = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    clf_trainall.fit(X_train, y_train)\n",
    "    with open(os.path.join(model_path, 'model_train_all_'+str(cv)+'.pickle'), 'wb') as f:\n",
    "        pickle.dump(clf_trainall, f, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With only two training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1,6):\n",
    "    X_train = pickle.load(open(os.path.join(data_path, 'X_train_'+str(cv)+'.pickle'), \"rb\" ))\n",
    "    y_train = pickle.load(open(os.path.join(data_path, 'y_train_'+str(cv)+'.pickle'), \"rb\" ))\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    with open(os.path.join(model_path, 'model_'+str(cv)+'_initial.pickle'), 'wb') as f:\n",
    "        pickle.dump(clf, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial model, and get its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6583333333333333\n",
      "starting precision:  1.0\n",
      "starting recall:  0.31666666666666665\n",
      "starting confusion matrix:  [[60  0]\n",
      " [41 19]]\n"
     ]
    }
   ],
   "source": [
    "clf = pickle.load(open(os.path.join(model_path, 'model_'+str(cv_round)+'_initial.pickle'), \"rb\" ))\n",
    "score = np.mean(clf.predict(X_test) == y_test)\n",
    "pred = clf.predict(X_test)\n",
    "starting_precision = precision_score(y_test,pred)\n",
    "starting_recall = recall_score(y_test,pred)\n",
    "starting_confusion_matrix = confusion_matrix(y_test,pred)\n",
    "print('accuracy: ', score)\n",
    "print('starting precision: ', starting_precision)\n",
    "print('starting recall: ', starting_recall)\n",
    "print('starting confusion matrix: ', starting_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize query strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertaity_with_moving_threshold(classifier, X_pool, threshold):\n",
    "    positive_probs = classifier.predict_proba(X_pool)[:,1]\n",
    "\n",
    "    # for each point, select the maximum uncertainty\n",
    "    uncertainty = 1-np.abs(threshold - positive_probs)\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_threshold_sampling(classifier, X_pool, threshold, n_instances=1):\n",
    "    uncertainty = uncertaity_with_moving_threshold(classifier, X_pool, threshold)\n",
    "    query_idx = multi_argmax(uncertainty, n_instances=n_instances)\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_classes(y_scores, t):\n",
    "    \"\"\"\n",
    "    This function adjusts class predictions based on the prediction threshold (t).\n",
    "    Will only work for binary classification problems.\n",
    "    \"\"\"\n",
    "    return [1 if y >= t else 0 for y in y_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_threshold(cv_round, thresholds, X_val, y_val, iterations=0):\n",
    "    fmeasures = []\n",
    "    for threshold in thresholds:\n",
    "        if iterations == 0:\n",
    "            model = pickle.load(open(os.path.join(model_path,'model_'+str(cv_round)+'_initial.pickle'), \"rb\" ))\n",
    "        else:\n",
    "            model = pickle.load(open(os.path.join(model_path,'model_'+str(cv_round)+'_'+str(iterations)+'.pickle'), \"rb\" ))\n",
    "            \n",
    "        pred_proba = model.predict_proba(X_val)\n",
    "        pred = adjusted_classes(pred_proba[:,1], threshold)\n",
    "        pred = np.array(pred)\n",
    "        fmeasures.append(f1_score(y_val, pred))\n",
    "        \n",
    "    f_measures = np.asarray(fmeasures)  \n",
    "    fmeasure_best = np.max(f_measures)    \n",
    "    threshold_best = thresholds[np.argmax(f_measures)]\n",
    "\n",
    "    return fmeasure_best, threshold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set audio_path\n",
    "audio_path = '/beegfs/work/sonyc/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(cv_round, n_queries, sampling_strategy=uncertainty_sampling):\n",
    "    #Load data\n",
    "    X_train = pickle.load(open(os.path.join(data_path, 'X_train_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    y_train = pickle.load(open(os.path.join(data_path, 'y_train_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    X_val = pickle.load(open(os.path.join(data_path, 'X_val_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    y_val = pickle.load(open(os.path.join(data_path, 'y_val_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    X_test = pickle.load(open(os.path.join(data_path, 'X_test_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    y_test = pickle.load(open(os.path.join(data_path, 'y_test_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    pool = pickle.load(open(os.path.join(data_path, 'X_pool_'+str(cv_round)+'.pickle'), \"rb\" ))\n",
    "    X_pool = pool[:, :128]\n",
    "    X_pool = X_pool.astype(int)\n",
    "    info_pool = pool[:, 128:]\n",
    "    \n",
    "    #Load initial classifier\n",
    "    clf = pickle.load(open(os.path.join(model_path, 'model_'+str(cv_round)+'_initial.pickle'), \"rb\" ))\n",
    "    pred = clf.predict(X_test)\n",
    "    starting_precision = precision_score(y_test,pred)\n",
    "    starting_recall = recall_score(y_test,pred)\n",
    "    starting_confusion_matrix = confusion_matrix(y_test,pred)\n",
    "    \n",
    "    #Initialize parameters\n",
    "    count = 1\n",
    "    queries = {}\n",
    "    best_fmeasures = []\n",
    "    best_thresholds = []\n",
    "    \n",
    "    #Initialize active leaner\n",
    "    learner = ActiveLearner(\n",
    "    estimator=clf,\n",
    "    query_strategy=sampling_strategy,\n",
    "    X_training=X_train, y_training=y_train\n",
    "    )\n",
    "    \n",
    "    #Active learning loop\n",
    "    while count < n_queries+1:\n",
    "        # For moving threshold strategy, use current best threshold to sample query\n",
    "        if sampling_strategy == moving_threshold_sampling:\n",
    "            thresholds = np.arange(0.1,0.9,0.01)\n",
    "            iterations = count-1\n",
    "            fmeasure_best, threshold_best = get_moving_threshold(cv_round, thresholds, X_val, y_val, iterations)\n",
    "            query_idx, query_instance = learner.query(X_pool, threshold=threshold_best)\n",
    "            best_fmeasures.append(fmeasure_best)\n",
    "            best_thresholds.append(threshold_best)\n",
    "    \n",
    "        else:\n",
    "            query_idx, query_instance = learner.query(X_pool)\n",
    "\n",
    "        sensor_id = info_pool[query_idx[0]][0]\n",
    "        timestamp = info_pool[query_idx[0]][1]\n",
    "        frame = int(info_pool[query_idx[0]][2])\n",
    "        filepath = info_pool[query_idx[0]][3]\n",
    "        \n",
    "        #If quried labeled data, use the label directly, otherwise get human annotation\n",
    "        if type(filepath) == int:\n",
    "            y_new = filepath\n",
    "        else:\n",
    "            decrypt_path = os.path.join(audio_path, filepath.split('/')[-2], filepath.split('/')[-1])\n",
    "            IPython.display.display(audio_decryption.decrypt_and_load_audio(decrypt_path, \n",
    "                                                                            sensor_id,\n",
    "                                                                            timestamp, \n",
    "                                                                            sample_rate=44100, \n",
    "                                                                            frame=frame, \n",
    "                                                                            url=, \n",
    "                                                                            cacert='/scratch/yw3004/projects/ICASSP2019-AL/CA.pem', \n",
    "                                                                            cert='/scratch/yw3004/projects/ICASSP2019-AL/yuwang-decrypt.pem',\n",
    "                                                                            key='/scratch/yw3004/projects/ICASSP2019-AL/<filename>_key.pem'))\n",
    "            print('query #: ', count)\n",
    "            y_new = input(\"Please input label for\\nsensor_id = '%s'\\ntimestamp = %s\\nframe = %d \\\n",
    "                          (1 if noise is present, 0 if noise is not present, 2 if not sure)\" \\\n",
    "                          % (sensor_id,timestamp,frame))\n",
    "        \n",
    "        #Teach learner with new assured quried label\n",
    "        if int(y_new) != 2:\n",
    "            learner.teach(\n",
    "                X=X_pool[query_idx],\n",
    "                y=np.array(y_new).reshape(-1, ))\n",
    "    \n",
    "            #update queries dictionary\n",
    "            if sensor_id not in list(queries.keys()):\n",
    "                queries[sensor_id] = np.array([timestamp, frame, y_new])\n",
    "            else:\n",
    "                queries[sensor_id] = np.vstack((queries[sensor_id],np.array([timestamp, frame, y_new])))\n",
    "            \n",
    "            #Save the model\n",
    "            with open(os.path.join(model_path, 'model_'+str(cv_round)+ '_'+str(count)+'.pickle'), 'wb') as f:\n",
    "                pickle.dump(learner, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "            count += 1\n",
    "            \n",
    "        #Update pool\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        info_pool = np.delete(info_pool, query_idx, axis=0)\n",
    "    \n",
    "    #save parameters\n",
    "    with open(os.path.join(project_path, 'evaluation', 'queries_'+str(cv_round)+ '.pickle'), 'wb') as f:\n",
    "        pickle.dump(queries, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    if sampling_strategy == moving_threshold_sampling:\n",
    "        with open(os.path.join(project_path, 'evaluation', 'best_fmeasures_'+str(cv_round)+ '.pickle'), 'wb') as f:\n",
    "            pickle.dump(best_fmeasures, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(project_path, 'evaluation', 'best_thresholds_'+str(cv_round)+ '.pickle'), 'wb') as f:\n",
    "            pickle.dump(best_thresholds, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return queries, best_fmeasures, best_thresholds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_learning",
   "language": "python",
   "name": "active_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
